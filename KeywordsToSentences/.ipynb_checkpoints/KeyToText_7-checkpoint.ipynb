{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4925a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import ftfy\n",
    "\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc88226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keytotext import trainer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a914fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_string(keywords):\n",
    "  string = \"\"\n",
    "  for kw in keywords:\n",
    "    if len(kw) > 1:\n",
    "      string = string + \" \" + kw.replace(\" \", \"_\")\n",
    "    else:\n",
    "      string = string + \" \" + kw\n",
    "\n",
    "  return string[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ba4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTarget(id):\n",
    "   if id == 1:\n",
    "    return \"Personal\"\n",
    "   elif id == 2:\n",
    "    return \"Physical\"\n",
    "   else:\n",
    "    return \"Cybersecurity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyWordOperation(stringa):\n",
    "  # Extract candidate for channel\n",
    "  count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([stringa])\n",
    "  all_candidates = count.get_feature_names()\n",
    "\n",
    "  candidate_tokens = tokenizer(all_candidates, padding=True, return_tensors=\"pt\")\n",
    "  candidate_embeddings = model(**candidate_tokens)[\"pooler_output\"]\n",
    "\n",
    "  text_tokens = tokenizer([stringa], padding=True, return_tensors=\"pt\")\n",
    "  text_embedding = model(**text_tokens)[\"pooler_output\"]\n",
    "\n",
    "  candidate_embeddings = candidate_embeddings.detach().numpy()\n",
    "  text_embedding = text_embedding.detach().numpy()\n",
    "\n",
    "  top_k = 7\n",
    "  distances = cosine_similarity(text_embedding, candidate_embeddings)\n",
    "  keywords = [all_candidates[index] for index in distances.argsort()[0][-top_k:]]\n",
    "\n",
    "  listaDiKeyChannel = extract_string(keywords)\n",
    "\n",
    "  return listaDiKeyChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = './dataset_completo.csv'\n",
    "\n",
    "col_names = ['triggerTitle','triggerChannelTitle','actionTitle','actionChannelTitle','title','desc','target','motivation']\n",
    "df = pd.read_csv(df_path,skiprows=1,sep=';',names=col_names,encoding = \"ISO-8859-1\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f451cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './training_dataset.csv'\n",
    "\n",
    "training_set = pd.read_csv(train_path,skiprows=1,sep=';',names=col_names,encoding = \"ISO-8859-1\")\n",
    "\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73951351",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './test_dataset.csv'\n",
    "\n",
    "test_set = pd.read_csv(test_path,skiprows=1,sep=';',names=col_names,encoding = \"ISO-8859-1\")\n",
    "\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = './val_dataset.csv'\n",
    "\n",
    "val_set = pd.read_csv(val_path,skiprows=1,sep=';',names=col_names,encoding = \"ISO-8859-1\")\n",
    "\n",
    "val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2294fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilroberta-base\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "n_gram_range = (1, 2)\n",
    "stop_words = \"english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84095943",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_training = []\n",
    "i = 0\n",
    "while i < len(training_set):\n",
    "  channel = \"if \"+ftfy.fix_text(training_set.iloc[i,0])+\"(\"+ftfy.fix_text(training_set.iloc[i,1])+\") then \"+ftfy.fix_text(training_set.iloc[i,2])+\"(\"+ftfy.fix_text(training_set.iloc[i,3])+\")\"\n",
    "  print(channel)\n",
    "  title = ftfy.fix_text(training_set.iloc[i,4])\n",
    "  print(title)\n",
    "  desc = ftfy.fix_text(training_set.iloc[i,5])\n",
    "  print(desc)\n",
    "\n",
    "  try:\n",
    "    listKeyChannel = keyWordOperation(channel)\n",
    "  except:\n",
    "    listKeyChannel = \"\"\n",
    "\n",
    "  try:  \n",
    "    listKeyTitle = keyWordOperation(title)\n",
    "  except:\n",
    "    listKeyTitle = \"\"\n",
    "\n",
    "  try:\n",
    "    listKeyDesc = keyWordOperation(desc)\n",
    "  except:\n",
    "    listKeyDesc = \"\"\n",
    "\n",
    "  keywords = \"\"+listKeyChannel+\" \"+listKeyTitle+\" \"+listKeyDesc+\" \"+getTarget(training_set.iloc[i,6])\n",
    "  #keywords = \"\"+listKeyChannel+\" \"+getTarget(training_set.iloc[i,6])\n",
    "  \n",
    "  listaTotSplit = keywords.split()\n",
    "  listaTot = \" \".join(sorted(set(listaTotSplit), key=listaTotSplit.index))\n",
    "\n",
    "  print(listaTot)\n",
    "    \n",
    "  keywords_training.append(listaTot)\n",
    "  print(i)\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'keywords':keywords_training, 'rule':training_set['desc'], 'text':training_set['motivation']})\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84cf0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keywords_test = []\n",
    "i = 0\n",
    "while i < len(test_set):\n",
    "  channel = \"if \"+ftfy.fix_text(test_set.iloc[i,0])+\"(\"+ftfy.fix_text(test_set.iloc[i,1])+\") then \"+ftfy.fix_text(test_set.iloc[i,2])+\"(\"+ftfy.fix_text(test_set.iloc[i,3])+\")\"\n",
    "  print(channel)\n",
    "  title = ftfy.fix_text(test_set.iloc[i,4])\n",
    "  print(title)\n",
    "  desc = ftfy.fix_text(test_set.iloc[i,5])\n",
    "  print(desc)\n",
    "\n",
    "  try:\n",
    "    listaDiKeyChannel = keyWordOperation(channel)\n",
    "  except:\n",
    "    listaDiKeyChannel = \"\"\n",
    "\n",
    "  try:  \n",
    "    listaDiKeyTitle = keyWordOperation(title)\n",
    "  except:\n",
    "    listaDiKeyTitle = \"\"\n",
    "\n",
    "  try:\n",
    "    listaDiKeyDesc = keyWordOperation(desc)\n",
    "  except:\n",
    "    listaDiKeyDesc = \"\"\n",
    "\n",
    "\n",
    "  keywords = \"\"+listaDiKeyChannel+\" \"+listaDiKeyTitle+\" \"+listaDiKeyDesc+\" \"+getTarget(test_set.iloc[i,6])\n",
    "\n",
    "  listaTotSplit = keywords.split()\n",
    "  listaTot = \" \".join(sorted(set(listaTotSplit), key=listaTotSplit.index))\n",
    "\n",
    "  print(listaTot)\n",
    "    \n",
    "  keywords_test.append(listaTot)\n",
    "  print(i)\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'keywords':keywords_test, 'rule':test_set['desc'], 'text':test_set['motivation']})\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7141197",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_val = []\n",
    "i = 0\n",
    "while i < len(val_set):\n",
    "  channel = \"if \"+ftfy.fix_text(val_set.iloc[i,0])+\"(\"+ftfy.fix_text(val_set.iloc[i,1])+\") then \"+ftfy.fix_text(val_set.iloc[i,2])+\"(\"+ftfy.fix_text(val_set.iloc[i,3])+\")\"\n",
    "  print(channel)\n",
    "  title = ftfy.fix_text(val_set.iloc[i,4])\n",
    "  print(title)\n",
    "  desc = ftfy.fix_text(val_set.iloc[i,5])\n",
    "  print(desc)\n",
    "\n",
    "  try:\n",
    "    listaDiKeyChannel = keyWordOperation(channel)\n",
    "  except:\n",
    "    listaDiKeyChannel = \"\"\n",
    "\n",
    "  try:  \n",
    "    listaDiKeyTitle = keyWordOperation(title)\n",
    "  except:\n",
    "    listaDiKeyTitle = \"\"\n",
    "\n",
    "  try:\n",
    "    listaDiKeyDesc = keyWordOperation(desc)\n",
    "  except:\n",
    "    listaDiKeyDesc = \"\"\n",
    "\n",
    "  keywords = \"\"+listaDiKeyChannel+\" \"+listaDiKeyTitle+\" \"+listaDiKeyDesc+\" \"+getTarget(val_set.iloc[i,6])\n",
    "\n",
    "  listaTotSplit = keywords.split()\n",
    "  listaTot = \" \".join(sorted(set(listaTotSplit), key=listaTotSplit.index))\n",
    "\n",
    "  print(listaTot)\n",
    "    \n",
    "  keywords_val.append(listaTot)\n",
    "  print(i)\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3758533",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame({'keywords':keywords_val, 'rule':val_set['desc'], 'text':val_set['motivation']})\n",
    "\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe7b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer()\n",
    "model.from_pretrained(model_name=\"t5-small\")\n",
    "model.train(train_df=train_df, test_df=val_df, batch_size=3, max_epochs=3,use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('./ModelKeyToText_evaluated_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer()\n",
    "model.load_model(\"./ModelKeyToText_evaluated_7\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_motivations = test_df['text']\n",
    "generated = []\n",
    "\n",
    "for i in range(0, len(test_df)):\n",
    "\n",
    "    keywords=[test_df['keywords'][i]]\n",
    "\n",
    "    print(\"Description: \", test_df['rule'][i])\n",
    "    print(\"Keywords extracted: \", keywords)\n",
    "    new_motivation = model.predict(keywords)\n",
    "    generated.append(new_motivation)\n",
    "    print(\"Gold motivation: \",test_df['text'][i])\n",
    "    print(\"New motivation: \", new_motivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['motivation_generated'] = generated\n",
    "\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5223b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.to_csv('test_set_results_T5_KeyToText_evaluated_7.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
